{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56936f7a-a1cc-4361-814c-c7554f778804",
   "metadata": {},
   "source": [
    "# DATA PREPARATION FOR BERTOPIC\n",
    "### Purpose: Prepare minimally processed text for BERTopic\n",
    "\n",
    "The initial baseline run involved minimal data cleaning and revealed that several topics were dominated by structural and boilerplate terms (e.g. “html”, “page”, “information”). This indicated the need for additional document-level cleaning and a re-run of the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde0ca5-da97-43ea-b4d6-761b84b48437",
   "metadata": {},
   "source": [
    "## Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affb16b6-b317-4936-afad-c39b41ccccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219bf75a-d9e1-4547-ad24-4648e7366dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c3d9ac-2b51-4f2e-b223-d1a4f1905111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your scraped corpus (after structural cleaning only)\n",
    "df = pd.read_csv('/workspaces/AM1_topic_modelling_BERTopic/data/full_retro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadc3377-39b1-4f85-ae21-d9f3a68833b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3972 documents\n",
      "\n",
      "Columns: ['url', 'title', 'date', 'text', 'source', 'type']\n",
      "\n",
      "Organisations: source\n",
      "schoolsweek    2742\n",
      "gov             702\n",
      "fft             202\n",
      "epi             115\n",
      "nuffield        107\n",
      "fed             104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date range: 2023-01-03 to 2026-01-08\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(df)} documents\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nOrganisations: {df['source'].value_counts()}\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b1409f-0546-4d2f-92fe-bab4f3a25520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://epi.org.uk/publications-and-research/w...</td>\n",
       "      <td>Early education and care and the private secto...</td>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>There have been significant shifts in the shap...</td>\n",
       "      <td>epi</td>\n",
       "      <td>think_tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://epi.org.uk/publications-and-research/e...</td>\n",
       "      <td>Edtech decision-making and inclusive practice:...</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>Education technology (edtech) is rising on the...</td>\n",
       "      <td>epi</td>\n",
       "      <td>think_tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://epi.org.uk/publications-and-research/w...</td>\n",
       "      <td>What you learn and what you earn: educational ...</td>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>Executive summary\\nDrawing on the Longitudinal...</td>\n",
       "      <td>epi</td>\n",
       "      <td>think_tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://epi.org.uk/publications-and-research/a...</td>\n",
       "      <td>A decade of degree apprenticeships</td>\n",
       "      <td>2025-11-12</td>\n",
       "      <td>Ten years on from their launch, degree apprent...</td>\n",
       "      <td>epi</td>\n",
       "      <td>think_tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://epi.org.uk/publications-and-research/y...</td>\n",
       "      <td>Youth degree apprenticeships: An alternative t...</td>\n",
       "      <td>2025-11-12</td>\n",
       "      <td>“Youth degree appr enticeships: An alternative...</td>\n",
       "      <td>epi</td>\n",
       "      <td>think_tank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://epi.org.uk/publications-and-research/w...   \n",
       "1  https://epi.org.uk/publications-and-research/e...   \n",
       "2  https://epi.org.uk/publications-and-research/w...   \n",
       "3  https://epi.org.uk/publications-and-research/a...   \n",
       "4  https://epi.org.uk/publications-and-research/y...   \n",
       "\n",
       "                                               title        date  \\\n",
       "0  Early education and care and the private secto...  2025-12-11   \n",
       "1  Edtech decision-making and inclusive practice:...  2025-12-04   \n",
       "2  What you learn and what you earn: educational ...  2025-11-20   \n",
       "3                 A decade of degree apprenticeships  2025-11-12   \n",
       "4  Youth degree apprenticeships: An alternative t...  2025-11-12   \n",
       "\n",
       "                                                text source        type  \n",
       "0  There have been significant shifts in the shap...    epi  think_tank  \n",
       "1  Education technology (edtech) is rising on the...    epi  think_tank  \n",
       "2  Executive summary\\nDrawing on the Longitudinal...    epi  think_tank  \n",
       "3  Ten years on from their launch, degree apprent...    epi  think_tank  \n",
       "4  “Youth degree appr enticeships: An alternative...    epi  think_tank  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7c53a-a43b-4aac-b000-a64ea027d0a7",
   "metadata": {},
   "source": [
    "## Minimal Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "314d71b5-6089-4a8f-8f6b-654928f8f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopwords after initial run of baseline  \n",
    "BOILERPLATE_TERMS = [\n",
    "    \"html\", \"page\", \"pages\", \"items\",\n",
    "    \"latest\", \"further\", \"information\",\n",
    "    \"related\", \"read\", \"more\"\n",
    "]\n",
    "\n",
    "def remove_boilerplate_terms(text):\n",
    "    pattern = r\"\\b(\" + \"|\".join(BOILERPLATE_TERMS) + r\")\\b\"\n",
    "    text = re.sub(pattern, \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794ba448-f082-4423-9b1b-3450547b6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_clean_for_bertopic(text):\n",
    "    \"\"\"\n",
    "    Light cleaning that preserves semantic context.\n",
    "    BERTopic works better with natural language, not heavily preprocessed text.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove URLs (optional - decide based on your needs)\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove multiple punctuation\n",
    "    text = re.sub(r'[.!?]{2,}', '.', text)\n",
    "    \n",
    "    # Remove special characters but keep sentence structure\n",
    "    text = re.sub(r'[^\\w\\s.!?,;:\\'-]', ' ', text)\n",
    "    \n",
    "    # Clean up spacing\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    text = remove_boilerplate_terms(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a1a84f-57f9-4c08-89ea-b692925a29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply minimal cleaning\n",
    "df['text_bertopic'] = df['text'].apply(minimal_clean_for_bertopic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1f1a0-566c-4e24-b044-7b7a611aa5f1",
   "metadata": {},
   "source": [
    "## Remove short documents (less than 20 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f678c17-873d-4f82-8385-650472e9a3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents before filtering: 3972\n",
      "Documents after filtering (>=20 words): 3970\n"
     ]
    }
   ],
   "source": [
    "# remove very short documents\n",
    "min_words = 20\n",
    "df['word_count'] = df['text_bertopic'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "print(f\"Documents before filtering: {len(df)}\")\n",
    "df = df[df['word_count'] >= min_words].copy()\n",
    "print(f\"Documents after filtering (>={min_words} words): {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d177f-0ce9-49ff-b08a-41adc436b34f",
   "metadata": {},
   "source": [
    "# data quality checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf8f089-6bff-438c-bcad-0097b74d4359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty documents: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for empty documents\n",
    "empty_docs = df['text_bertopic'].isna() | (df['text_bertopic'] == '')\n",
    "print(f\"Empty documents: {empty_docs.sum()}\")\n",
    "\n",
    "if empty_docs.sum() > 0:\n",
    "    print(\"Removing empty documents...\")\n",
    "    df = df[~empty_docs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc04608-6b83-4b96-bf78-9d908cff0a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text length statistics (character count):\n",
      "count     3970.000000\n",
      "mean      4144.261461\n",
      "std       2862.053007\n",
      "min        134.000000\n",
      "25%       2457.000000\n",
      "50%       3764.000000\n",
      "75%       4964.000000\n",
      "max      33457.000000\n",
      "Name: char_count, dtype: float64\n",
      "\n",
      "Word count statistics:\n",
      "count    3970.000000\n",
      "mean      682.335013\n",
      "std       482.220701\n",
      "min        20.000000\n",
      "25%       401.000000\n",
      "50%       615.000000\n",
      "75%       818.000000\n",
      "max      5574.000000\n",
      "Name: final_word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check text length distribution\n",
    "print(\"\\nText length statistics (character count):\")\n",
    "df['char_count'] = df['text_bertopic'].str.len()\n",
    "print(df['char_count'].describe())\n",
    "\n",
    "print(\"\\nWord count statistics:\")\n",
    "df['final_word_count'] = df['text_bertopic'].apply(lambda x: len(str(x).split()))\n",
    "print(df['final_word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314432cd-1db1-47ea-a353-5b5952e42e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random sample of cleaned documents:\n",
      "\n",
      "Organisation: schoolsweek\n",
      "Date: 2025-03-26\n",
      "Text (first 200 chars): The Treasury must restore 3.6 billion in lost capital funding, leaders have said, as teachers reported widespread problems with their school buildings. The chancellor Rachel Reeves will deliver her sp...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Organisation: schoolsweek\n",
      "Date: 2024-02-06\n",
      "Text (first 200 chars): Ofsted has rejected calls to automatically exempt schools with RAAC from inspection, but urged leaders to use its deferral policy if they get the call. In the autumn term, the watchdogremoved all scho...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Organisation: schoolsweek\n",
      "Date: 2024-07-18\n",
      "Text (first 200 chars): There will be 260,000 pupils in schools than previously predicted by 2028, the Department for Education has estimated, revising up its projections in response to new data. Last year s pupil number pro...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandom sample of cleaned documents:\")\n",
    "for idx in df.sample(3).index:\n",
    "    print(f\"\\nOrganisation: {df.loc[idx, 'source']}\")\n",
    "    print(f\"Date: {df.loc[idx, 'date']}\")\n",
    "    print(f\"Text (first 200 chars): {df.loc[idx, 'text_bertopic'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474def1-3c27-44cc-97fd-558ed4587fc1",
   "metadata": {},
   "source": [
    "## Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3b8fca-99a6-40c3-9706-d940b62d2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final clean dataset\n",
    "df_final = df[[\n",
    "    'text_bertopic',  # Main text for BERTopic\n",
    "    'date',\n",
    "    'source',\n",
    "    'type'\n",
    "]].copy()\n",
    "\n",
    "df_final.rename(columns={'text_bertopic': 'text'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6491fcf8-274f-476b-a647-76f8041c2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df_final['date'] = pd.to_datetime(df_final['date'])\n",
    "\n",
    "# Sort by date\n",
    "df_final = df_final.sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6382561-a601-46de-841e-26461e19deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add document ID\n",
    "df_final['doc_id'] = range(len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a614dce-e0d4-4753-9789-4e54b681baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved cleaned corpus to: /workspaces/AM1_topic_modelling_BERTopic/data/bertopic_model_input.csv\n"
     ]
    }
   ],
   "source": [
    "# save cleaned data\n",
    "output_path = '/workspaces/AM1_topic_modelling_BERTopic/data/bertopic_model_input.csv'\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved cleaned corpus to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c5a7368-0707-4971-860e-9f36b7da9c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to: data/bertopic_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['doc_id', 'date', 'source', 'type']\n",
    "df_final[metadata_cols].to_csv('/workspaces/AM1_topic_modelling_BERTopic/data/bertopic_metadata.csv', index=False)\n",
    "print(f\"Saved metadata to: data/bertopic_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bc1424-7743-4b12-8c7f-20c61b7fceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total documents: 3970\n",
      "Date range: 2023-01-03 00:00:00 to 2026-01-08 00:00:00\n",
      "\n",
      "Documents by organisation:\n",
      "source\n",
      "schoolsweek    2742\n",
      "gov             702\n",
      "fft             202\n",
      "epi             115\n",
      "nuffield        107\n",
      "fed             102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Documents by organisation type:\n",
      "type\n",
      "ed_journalism    2742\n",
      "gov_inst          702\n",
      "think_tank        222\n",
      "ed_res_org        202\n",
      "prof_body         102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average document length: 4144 characters\n",
      "Median document length: 3764 characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal documents: {len(df_final)}\")\n",
    "print(f\"Date range: {df_final['date'].min()} to {df_final['date'].max()}\")\n",
    "print(f\"\\nDocuments by organisation:\")\n",
    "print(df_final['source'].value_counts())\n",
    "print(f\"\\nDocuments by organisation type:\")\n",
    "print(df_final['type'].value_counts())\n",
    "print(f\"\\nAverage document length: {df_final['text'].str.len().mean():.0f} characters\")\n",
    "print(f\"Median document length: {df_final['text'].str.len().median():.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb52cae-98e2-4a5f-823e-0d2948070ccc",
   "metadata": {},
   "source": [
    "## Comparison between NMF And BERTopic cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f7feb5-99ae-4a49-8f5e-e792417ab96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BERTOPIC vs NMF PREPROCESSING COMPARISON\n",
      "================================================================================\n",
      "\n",
      "KEY DIFFERENCES BETWEEN BERTOPIC AND NMF PREPROCESSING:\n",
      "\n",
      "NMF Preprocessing (Heavy):\n",
      "- Lowercase all text\n",
      "- Remove all punctuation\n",
      "- Tokenisation and lemmatisation\n",
      "- Aggressive stopword removal\n",
      "- POS filtering (only nouns, proper nouns, adjectives)\n",
      "- Domain-specific stopword lists\n",
      "→ Result: \"teacher recruitment school pupil england\"\n",
      "\n",
      "BERTopic Preprocessing (Minimal):\n",
      "- Preserve sentence structure\n",
      "- Keep punctuation and capitalisation\n",
      "- Keep person entities (for baseline model- revisit this at a later stage depending on model output)\n",
      "- No lemmatisation or stemming\n",
      "- No explicit stopword removal\n",
      "→ Result: \"The teacher recruitment crisis in schools across England \n",
      "   has affected pupil outcomes.\"\n",
      "\n",
      "WHY THE DIFFERENCE?\n",
      "- NMF uses bag-of-words (TF-IDF) → needs clean tokens\n",
      "- BERTopic uses sentence embeddings → needs semantic context\n",
      "- Transformers understand grammar, syntax, and context\n",
      "- Over-cleaning removes information that embeddings use\n",
      "\n",
      "TRADE-OFFS:\n",
      "- BERTopic: Better semantic understanding, more contextual topics\n",
      "- NMF: More interpretable individual words, faster processing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BERTOPIC vs NMF PREPROCESSING COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_text = \"\"\"\n",
    "KEY DIFFERENCES BETWEEN BERTOPIC AND NMF PREPROCESSING:\n",
    "\n",
    "NMF Preprocessing (Heavy):\n",
    "- Lowercase all text\n",
    "- Remove all punctuation\n",
    "- Tokenisation and lemmatisation\n",
    "- Aggressive stopword removal\n",
    "- POS filtering (only nouns, proper nouns, adjectives)\n",
    "- Domain-specific stopword lists\n",
    "→ Result: \"teacher recruitment school pupil england\"\n",
    "\n",
    "BERTopic Preprocessing (Minimal):\n",
    "- Preserve sentence structure\n",
    "- Keep punctuation and capitalisation\n",
    "- Keep person entities (for baseline model- revisit this at a later stage depending on model output)\n",
    "- No lemmatisation or stemming\n",
    "- No explicit stopword removal\n",
    "→ Result: \"The teacher recruitment crisis in schools across England \n",
    "   has affected pupil outcomes.\"\n",
    "\n",
    "WHY THE DIFFERENCE?\n",
    "- NMF uses bag-of-words (TF-IDF) → needs clean tokens\n",
    "- BERTopic uses sentence embeddings → needs semantic context\n",
    "- Transformers understand grammar, syntax, and context\n",
    "- Over-cleaning removes information that embeddings use\n",
    "\n",
    "TRADE-OFFS:\n",
    "- BERTopic: Better semantic understanding, more contextual topics\n",
    "- NMF: More interpretable individual words, faster processing\n",
    "\"\"\"\n",
    "\n",
    "print(comparison_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
